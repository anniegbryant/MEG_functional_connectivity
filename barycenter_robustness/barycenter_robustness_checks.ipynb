{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "# Statistics\n",
    "from tslearn import barycenters\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Classification\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold, cross_validate, StratifiedKFold, LeaveOneOut, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# add path to classification analysis functions\n",
    "from mixed_sigmoid_normalisation import MixedSigmoidScaler\n",
    "\n",
    "# Add ../data_visualization to path, then import kl_divergence_from_counts\n",
    "# add path to classification analysis functions\n",
    "sys.path.insert(0, './data_visualization/')\n",
    "from kl_divergence_from_counts import kl_divergence_from_counts\n",
    "\n",
    "# Add rpy2\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(broom)\n",
    "    library(cowplot)\n",
    "    library(glue)\n",
    "    library(patchwork)\n",
    "    library(see)\n",
    "    library(tidyverse)\n",
    "})\n",
    "\n",
    "# Set cowplot theme\n",
    "theme_set(theme_cowplot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pyspi SPI info\n",
    "pyspi_SPI_info = pd.read_csv(\"../feature_extraction/pyspi_SPI_info.csv\")\n",
    "\n",
    "# Define path for derivatives directory\n",
    "deriv_dir = \"/Users/abry4213/data/Cogitate_MEG/derivatives\"\n",
    "\n",
    "# Initialize list for pyspi results\n",
    "all_time_resolved_barycenter_res_list = []\n",
    "\n",
    "# Load in time-resolved barycenter results\n",
    "for barycenter_time_res_file in glob(f\"{deriv_dir}/time_series_features/averaged_epochs/*pyspi_barycenter_sq*.csv\"):\n",
    "    barycenter_time_resolved_res = pd.read_csv(barycenter_time_res_file)\n",
    "    all_time_resolved_barycenter_res_list.append(barycenter_time_resolved_res)\n",
    "\n",
    "# Concatenate pyspi results\n",
    "all_time_resolved_barycenter_res = pd.concat(all_time_resolved_barycenter_res_list)\n",
    "\n",
    "# Separate out into raw and absolute value time series and make sure SPI ends with \"_max\"\n",
    "all_raw_time_resolved_barycenter_res = all_time_resolved_barycenter_res.query(\"Data_Type=='Raw' & SPI.str.endswith('_max')\")\n",
    "all_abs_time_resolved_barycenter_res = all_time_resolved_barycenter_res.query(\"Data_Type=='Abs' & SPI.str.endswith('_max')\")\n",
    "\n",
    "all_raw_time_resolved_barycenter_res.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness check 1: stimulus classification with raw vs. absolute value time series before computing barycenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier\n",
    "model = LogisticRegression(penalty='l1', C=1, solver='liblinear', class_weight='balanced', random_state=127)\n",
    "\n",
    "pipe = Pipeline([('scaler', MixedSigmoidScaler(unit_variance=True)), \n",
    "                            ('model', model)])\n",
    "\n",
    "# Define scoring type\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'balanced_accuracy': 'balanced_accuracy',\n",
    "           'AUC': make_scorer(roc_auc_score, response_method='predict_proba')}\n",
    "\n",
    "# meta-ROI comparisons\n",
    "meta_ROIs = [\"Category_Selective\", \"IPS\", \"Prefrontal_Cortex\", \"V1_V2\"]\n",
    "\n",
    "# Manually define combinations\n",
    "meta_roi_comparisons = [(\"Category_Selective\", \"IPS\"),\n",
    "                        (\"Category_Selective\", \"Prefrontal_Cortex\"),\n",
    "                        (\"Category_Selective\", \"V1_V2\"),\n",
    "                        (\"IPS\", \"Category_Selective\"),\n",
    "                        (\"Prefrontal_Cortex\", \"Category_Selective\"),\n",
    "                        (\"V1_V2\", \"Category_Selective\")]\n",
    "\n",
    "# Relevance type comparisons\n",
    "relevance_type_comparisons = [\"Relevant non-target\", \"Irrelevant\"]\n",
    "\n",
    "# Stimulus presentation comparisons\n",
    "stimulus_presentation_comparisons = [\"on\", \"off\"]\n",
    "\n",
    "# Define all combinations for cross-task classification\n",
    "group_stratified_CV = StratifiedGroupKFold(n_splits = 10, shuffle = True, random_state=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stimulus type comparisons\n",
    "stimulus_types = all_raw_time_resolved_barycenter_res.stimulus_type.unique().tolist()\n",
    "stimulus_type_comparisons = list(itertools.combinations(stimulus_types, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abs_time_resolved_barycenter_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All comparisons list\n",
    "comparing_between_stimulus_types_classification_results_list = []\n",
    "\n",
    "for relevance_type in relevance_type_comparisons:\n",
    "    print(\"Relevance type:\" + str(relevance_type))\n",
    "    for stimulus_presentation in stimulus_presentation_comparisons:\n",
    "        print(\"Stimulus presentation:\" + str(stimulus_presentation))\n",
    "\n",
    "        # First, look at each meta-ROI pair separately# First, look at each meta-ROI pair separately\n",
    "        for meta_roi_comparison in meta_roi_comparisons:\n",
    "            print(\"ROI Comparison:\" + str(meta_roi_comparison))\n",
    "            ROI_from, ROI_to = meta_roi_comparison\n",
    "\n",
    "            # Finally, we get to the final dataset\n",
    "            roi_pair_wise_dataset_for_classification = (all_abs_time_resolved_barycenter_res.query(\"meta_ROI_from==@ROI_from & meta_ROI_to==@ROI_to & relevance_type == @relevance_type & stimulus_presentation == @stimulus_presentation\")\n",
    "                                                        .reset_index(drop=True))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_helper(this_statistic_data, num_rows):\n",
    "    # Extract SPI values and fix NaN\n",
    "    this_raw_column_data = this_statistic_data['value']\n",
    "    num_NaN = this_raw_column_data.isna().sum()\n",
    "    prop_NaN = num_NaN / num_rows\n",
    "\n",
    "    # If 0% < num_NaN < 10%, impute by the mean of each component\n",
    "    if 0 < prop_NaN < 0.1:\n",
    "        values_imputed = (this_raw_column_data\n",
    "                            .transform(lambda x: x.fillna(x.mean())))\n",
    "\n",
    "        this_raw_column_data = values_imputed\n",
    "        this_statistic_data[\"value\"] = this_raw_column_data\n",
    "\n",
    "    return this_statistic_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All comparisons list\n",
    "n_jobs = 1\n",
    "comparing_between_stimulus_types_classification_results_list = []\n",
    "\n",
    "for relevance_type in relevance_type_comparisons:\n",
    "    print(\"Relevance type:\" + str(relevance_type))\n",
    "    for stimulus_presentation in stimulus_presentation_comparisons:\n",
    "        print(\"Stimulus presentation:\" + str(stimulus_presentation))\n",
    "\n",
    "        # First, look at each meta-ROI pair separately# First, look at each meta-ROI pair separately\n",
    "        for meta_roi_comparison in meta_roi_comparisons:\n",
    "            print(\"ROI Comparison:\" + str(meta_roi_comparison))\n",
    "            ROI_from, ROI_to = meta_roi_comparison\n",
    "\n",
    "            # Finally, we get to the final dataset\n",
    "            roi_abs_pair_wise_dataset_for_classification = (all_abs_time_resolved_barycenter_res.query(\"meta_ROI_from==@ROI_from & meta_ROI_to==@ROI_to & relevance_type == @relevance_type & stimulus_presentation == @stimulus_presentation\")\n",
    "                                                        .reset_index(drop=True))\n",
    "            \n",
    "            roi_raw_pair_wise_dataset_for_classification = (all_raw_time_resolved_barycenter_res.query(\"meta_ROI_from==@ROI_from & meta_ROI_to==@ROI_to & relevance_type == @relevance_type & stimulus_presentation == @stimulus_presentation\")\n",
    "                                                        .reset_index(drop=True))\n",
    "            \n",
    "            for this_SPI in roi_abs_pair_wise_dataset_for_classification.SPI.unique():\n",
    "                    print(f\"Processing {this_SPI}\")\n",
    "\n",
    "                    # Extract this SPI\n",
    "                    this_raw_statistic_data = roi_raw_pair_wise_dataset_for_classification.query(f\"SPI == '{this_SPI}'\")\n",
    "                    this_abs_statistic_data = roi_abs_pair_wise_dataset_for_classification.query(f\"SPI == '{this_SPI}'\")\n",
    "\n",
    "                    # Find overall number of rows\n",
    "                    num_rows = this_raw_statistic_data.shape[0]\n",
    "\n",
    "                    # Imputation\n",
    "                    this_raw_statistic_data = impute_helper(this_raw_statistic_data, num_rows)\n",
    "                    this_abs_statistic_data = impute_helper(this_abs_statistic_data, num_rows)\n",
    "                    \n",
    "                    # Start an empty list for the classification results\n",
    "                    stat_combo_res_list = []\n",
    "                \n",
    "                    # Iterate over stimulus combos\n",
    "                    for this_combo in stimulus_type_comparisons:\n",
    "\n",
    "                        # Subset data to the corresponding stimulus pairs\n",
    "                        final_raw_dataset_for_classification_this_combo = this_raw_statistic_data.query(f\"stimulus_type in {this_combo}\")\n",
    "                        final_abs_dataset_for_classification_this_combo = this_abs_statistic_data.query(f\"stimulus_type in {this_combo}\")\n",
    "\n",
    "                        # Fit classifier\n",
    "                        X_raw = final_raw_dataset_for_classification_this_combo.value.to_numpy().reshape(-1, 1)\n",
    "                        y_raw = final_raw_dataset_for_classification_this_combo.stimulus_type.to_numpy().reshape(-1, 1)\n",
    "                        groups_raw = final_raw_dataset_for_classification_this_combo.subject_ID.to_numpy().reshape(-1, 1)\n",
    "                        groups_raw_flat = np.array([str(item[0]) for item in groups_raw])\n",
    "\n",
    "                        X_abs = final_abs_dataset_for_classification_this_combo.value.to_numpy().reshape(-1, 1)\n",
    "                        y_abs = final_abs_dataset_for_classification_this_combo.stimulus_type.to_numpy().reshape(-1, 1)\n",
    "                        groups_abs = final_abs_dataset_for_classification_this_combo.subject_ID.to_numpy().reshape(-1, 1)\n",
    "                        groups_abs_flat = np.array([str(item[0]) for item in groups_abs])\n",
    "\n",
    "                        # Make a deepcopy of the pipeline\n",
    "                        this_iter_pipe_raw = deepcopy(pipe)\n",
    "                        this_classifier_res_raw = cross_validate(this_iter_pipe_raw, X_raw, y_raw, groups=groups_raw_flat, cv=group_stratified_CV, scoring=scoring, n_jobs=n_jobs, \n",
    "                                                                    return_estimator=False, return_train_score=False)\n",
    "                        this_SPI_combo_df_raw = pd.DataFrame({\"SPI\": [this_SPI], \n",
    "                                \"classifier\": [\"Logistic Regression\"],\n",
    "                                \"Data_Type\": ['Raw'],\n",
    "                                \"Region_Pair\": [f\"{ROI_from}__{ROI_to}\"],\n",
    "                                \"relevance_type\": [relevance_type],\n",
    "                                \"stimulus_presentation\": [stimulus_presentation],\n",
    "                                \"stimulus_combo\": [this_combo], \n",
    "                                \"accuracy\": [this_classifier_res_raw['test_accuracy'].mean()],\n",
    "                                \"accuracy_SD\": [this_classifier_res_raw['test_accuracy'].std()]})\n",
    "                        \n",
    "                        # Append to growing results list\n",
    "                        comparing_between_stimulus_types_classification_results_list.append(this_SPI_combo_df_raw)\n",
    "                        \n",
    "                        this_iter_pipe_abs = deepcopy(pipe)\n",
    "                        this_classifier_res_abs = cross_validate(this_iter_pipe_abs, X_abs, y_abs, groups=groups_abs_flat, cv=group_stratified_CV, scoring=scoring, n_jobs=n_jobs, \n",
    "                                                                    return_estimator=False, return_train_score=False)\n",
    "                        this_SPI_combo_df_abs = pd.DataFrame({\"SPI\": [this_SPI],\n",
    "                                \"classifier\": [\"Logistic Regression\"],\n",
    "                                \"Data_Type\": ['Abs'],\n",
    "                                \"Region_Pair\": [f\"{ROI_from}__{ROI_to}\"],\n",
    "                                \"relevance_type\": [relevance_type],\n",
    "                                \"stimulus_presentation\": [stimulus_presentation],\n",
    "                                \"stimulus_combo\": [this_combo], \n",
    "                                \"accuracy\": [this_classifier_res_abs['test_accuracy'].mean()],\n",
    "                                \"accuracy_SD\": [this_classifier_res_abs['test_accuracy'].std()]})\n",
    "                        \n",
    "                        # Append to growing results list\n",
    "                        comparing_between_stimulus_types_classification_results_list.append(this_SPI_combo_df_abs)\n",
    "                        \n",
    "\n",
    "comparing_between_stimulus_types_classification_results = pd.concat(comparing_between_stimulus_types_classification_results_list).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPI</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Region_Pair</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>stimulus_presentation</th>\n",
       "      <th>stimulus_combo</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bary-sq_euclidean_max</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Category_Selective__IPS</td>\n",
       "      <td>Relevant non-target</td>\n",
       "      <td>on</td>\n",
       "      <td>(False, face)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bary-sq_euclidean_max</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Abs</td>\n",
       "      <td>Category_Selective__IPS</td>\n",
       "      <td>Relevant non-target</td>\n",
       "      <td>on</td>\n",
       "      <td>(False, face)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bary-sq_euclidean_max</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Category_Selective__IPS</td>\n",
       "      <td>Relevant non-target</td>\n",
       "      <td>on</td>\n",
       "      <td>(False, letter)</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bary-sq_euclidean_max</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Abs</td>\n",
       "      <td>Category_Selective__IPS</td>\n",
       "      <td>Relevant non-target</td>\n",
       "      <td>on</td>\n",
       "      <td>(False, letter)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bary-sq_euclidean_max</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Category_Selective__IPS</td>\n",
       "      <td>Relevant non-target</td>\n",
       "      <td>on</td>\n",
       "      <td>(False, object)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SPI           classifier Data_Type  \\\n",
       "0  bary-sq_euclidean_max  Logistic Regression       Raw   \n",
       "1  bary-sq_euclidean_max  Logistic Regression       Abs   \n",
       "2  bary-sq_euclidean_max  Logistic Regression       Raw   \n",
       "3  bary-sq_euclidean_max  Logistic Regression       Abs   \n",
       "4  bary-sq_euclidean_max  Logistic Regression       Raw   \n",
       "\n",
       "               Region_Pair       relevance_type stimulus_presentation  \\\n",
       "0  Category_Selective__IPS  Relevant non-target                    on   \n",
       "1  Category_Selective__IPS  Relevant non-target                    on   \n",
       "2  Category_Selective__IPS  Relevant non-target                    on   \n",
       "3  Category_Selective__IPS  Relevant non-target                    on   \n",
       "4  Category_Selective__IPS  Relevant non-target                    on   \n",
       "\n",
       "    stimulus_combo  accuracy  accuracy_SD  \n",
       "0    (False, face)  0.500000     0.000000  \n",
       "1    (False, face)  0.500000     0.000000  \n",
       "2  (False, letter)  0.511111     0.022222  \n",
       "3  (False, letter)  0.500000     0.000000  \n",
       "4  (False, object)  0.500000     0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparing_between_stimulus_types_classification_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abry4213/miniforge3/envs/annie_env/lib/python3.9/site-packages/rpy2/robjects/pandas2ri.py:65: UserWarning: Error while trying to convert the column \"stimulus_combo\". Fall back to string conversion. The error is: <class 'tuple'>\n",
      "  warnings.warn('Error while trying to convert '\n"
     ]
    }
   ],
   "source": [
    "%%R -i comparing_between_stimulus_types_classification_results\n",
    "\n",
    "comparing_between_stimulus_types_classification_results %>% \n",
    "    mutate(stat_identifier = glue(\"{SPI}_{Region_Pair}_{relevance_type}_{stimulus_presentation}_{stimulus_combo}\")) %>%\n",
    "    ggplot(data=., mapping=aes(x=Data_Type, y=100*accuracy)) +\n",
    "    ylab(\"Cross-validated accuracy (%)\") +\n",
    "    scale_x_discrete(expand=c(0.05, 0.05)) +\n",
    "    geom_line(aes(group=stat_identifier), color=\"black\", alpha=0.2)  +\n",
    "    geom_point() \n",
    "ggsave(\"../plots/modeling/Barycenter_empirical_performance_abs_vs_raw.svg\", width=3.5, height=4, units='in', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness check 2: model vs. empirical alignment with different geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list for pyspi results\n",
    "all_time_resolved_barycenter_res_list = []\n",
    "\n",
    "# Load in time-resolved barycenter results\n",
    "for barycenter_time_res_file in glob(f\"{deriv_dir}/time_series_features/averaged_epochs/*pyspi_barycenter_sq*.csv\"):\n",
    "    barycenter_time_resolved_res = pd.read_csv(barycenter_time_res_file)\n",
    "    all_time_resolved_barycenter_res_list.append(barycenter_time_resolved_res)\n",
    "\n",
    "# Concatenate pyspi results\n",
    "all_time_resolved_barycenter_res = pd.concat(all_time_resolved_barycenter_res_list)\n",
    "\n",
    "# Separate out into raw and absolute value time series and make sure SPI ends with \"_max\"\n",
    "all_abs_time_resolved_barycenter_res = (all_time_resolved_barycenter_res\n",
    "                                        .query(\"Data_Type=='Abs' & SPI.str.endswith('_max_time') & meta_ROI_from == 'Category_Selective' & meta_ROI_to in ['V1_V2', 'Prefrontal_Cortex']\")\n",
    "                                        .assign(SPI = lambda x: x['SPI'].str.replace('_max_time', '').str.replace('_max', ''),\n",
    "                                                Model = lambda x: np.where(x.meta_ROI_to == 'V1_V2', 'IIT', 'GNWT'))\n",
    ")\n",
    "\n",
    "all_model_pyspi_res_list = []\n",
    "for noise_level in [1]:\n",
    "    GNWT_stim_on_pyspi_barycenter_res = pd.read_csv(f\"../modeling/barycenter_results/GNWT_stim_on_sims_all_pyspi_barycenter_sq_results_noise_{noise_level}.csv\")\n",
    "    GNWT_stim_off_pyspi_barycenter_res = pd.read_csv(f\"../modeling/barycenter_results/GNWT_stim_off_sims_all_pyspi_barycenter_sq_results_noise_{noise_level}.csv\")\n",
    "    IIT_stim_on_pyspi_barycenter_res = pd.read_csv(f\"../modeling/barycenter_results/IIT_stim_on_sims_all_pyspi_barycenter_sq_results_noise_{noise_level}.csv\")\n",
    "    IIT_stim_off_pyspi_barycenter_res = pd.read_csv(f\"../modeling/barycenter_results/IIT_stim_off_sims_all_pyspi_barycenter_sq_results_noise_{noise_level}.csv\")\n",
    "\n",
    "    noise_level_pyspi_res = (pd.concat([GNWT_stim_on_pyspi_barycenter_res,\n",
    "                                        GNWT_stim_off_pyspi_barycenter_res,\n",
    "                                        IIT_stim_on_pyspi_barycenter_res,\n",
    "                                        IIT_stim_off_pyspi_barycenter_res])\n",
    "                            .query(\"meta_ROI_from == 'Category_Selective'\")\n",
    "                            .assign(SPI_stat = lambda x: np.where(x['SPI'].str.contains('_max_time'), 'max_time', 'max'),\n",
    "                                    SPI = lambda x: x['SPI'].str.replace('_max_time', '').str.replace('_max', ''),\n",
    "                                    Model = lambda x: x['sim_context'].str.split('_stim').str[0],\n",
    "                                    stimulus_presentationulus_Presentation = lambda x: x['sim_context'].str.split('stim_').str[1])\n",
    "                            .rename(columns={'stimulus_presentationulus_Presentation': 'stimulus_presentation'})\n",
    "                            .drop(columns=['sim_context'])\n",
    "                            .query(\"SPI_stat=='max_time' & Data_Type == 'Abs'\")\n",
    "    )\n",
    "\n",
    "    # Add noise column if it doesn't exist\n",
    "    if 'Noise' not in noise_level_pyspi_res.columns:\n",
    "        noise_level_pyspi_res['Noise'] = noise_level\n",
    "    else:\n",
    "        noise_level_pyspi_res = noise_level_pyspi_res.query(\"Noise==@noise_level\")\n",
    "\n",
    "    # Append to list\n",
    "    all_model_pyspi_res_list.append(noise_level_pyspi_res)\n",
    "\n",
    "# Concatenate results\n",
    "all_model_pyspi_res = pd.concat(all_model_pyspi_res_list)\n",
    "\n",
    "\n",
    "# Combine\n",
    "model_vs_empirical_across_geometries = pd.concat([all_abs_time_resolved_barycenter_res.assign(Data_Type = \"Empirical\"), all_model_pyspi_res.assign(Data_Type = \"Model\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SPI</th>\n",
       "      <th>meta_ROI_from</th>\n",
       "      <th>meta_ROI_to</th>\n",
       "      <th>value</th>\n",
       "      <th>stimulus_type</th>\n",
       "      <th>relevance_type</th>\n",
       "      <th>duration</th>\n",
       "      <th>stimulus_presentation</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>subject_ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Noise</th>\n",
       "      <th>sim_num</th>\n",
       "      <th>SPI_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>40.0</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>Category_Selective</td>\n",
       "      <td>Prefrontal_Cortex</td>\n",
       "      <td>173.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>on</td>\n",
       "      <td>Empirical</td>\n",
       "      <td>CA124</td>\n",
       "      <td>GNWT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>44.0</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>Category_Selective</td>\n",
       "      <td>V1_V2</td>\n",
       "      <td>334.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>on</td>\n",
       "      <td>Empirical</td>\n",
       "      <td>CA124</td>\n",
       "      <td>IIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>88.0</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>Category_Selective</td>\n",
       "      <td>Prefrontal_Cortex</td>\n",
       "      <td>173.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>on</td>\n",
       "      <td>Empirical</td>\n",
       "      <td>CA124</td>\n",
       "      <td>GNWT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>92.0</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>Category_Selective</td>\n",
       "      <td>V1_V2</td>\n",
       "      <td>192.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>on</td>\n",
       "      <td>Empirical</td>\n",
       "      <td>CA124</td>\n",
       "      <td>IIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>136.0</td>\n",
       "      <td>bary-sq_sgddtw</td>\n",
       "      <td>Category_Selective</td>\n",
       "      <td>Prefrontal_Cortex</td>\n",
       "      <td>173.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>on</td>\n",
       "      <td>Empirical</td>\n",
       "      <td>CA124</td>\n",
       "      <td>GNWT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                SPI       meta_ROI_from        meta_ROI_to  value  \\\n",
       "174   40.0  bary-sq_euclidean  Category_Selective  Prefrontal_Cortex  173.0   \n",
       "177   44.0  bary-sq_euclidean  Category_Selective              V1_V2  334.0   \n",
       "210   88.0        bary-sq_dtw  Category_Selective  Prefrontal_Cortex  173.0   \n",
       "213   92.0        bary-sq_dtw  Category_Selective              V1_V2  192.0   \n",
       "246  136.0     bary-sq_sgddtw  Category_Selective  Prefrontal_Cortex  173.0   \n",
       "\n",
       "    stimulus_type relevance_type  duration stimulus_presentation  Data_Type  \\\n",
       "174         False     Irrelevant    1000.0                    on  Empirical   \n",
       "177         False     Irrelevant    1000.0                    on  Empirical   \n",
       "210         False     Irrelevant    1000.0                    on  Empirical   \n",
       "213         False     Irrelevant    1000.0                    on  Empirical   \n",
       "246         False     Irrelevant    1000.0                    on  Empirical   \n",
       "\n",
       "    subject_ID Model  Noise  sim_num SPI_stat  \n",
       "174      CA124  GNWT    NaN      NaN      NaN  \n",
       "177      CA124   IIT    NaN      NaN      NaN  \n",
       "210      CA124  GNWT    NaN      NaN      NaN  \n",
       "213      CA124   IIT    NaN      NaN      NaN  \n",
       "246      CA124  GNWT    NaN      NaN      NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vs_empirical_across_geometries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>SPI</th>\n",
       "      <th>stimulus_presentation</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>KL_Divergence</th>\n",
       "      <th>WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>27.971548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.261054</td>\n",
       "      <td>22.107636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.289872</td>\n",
       "      <td>33.030310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.205493</td>\n",
       "      <td>25.614307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_sgddtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.264105</td>\n",
       "      <td>39.033546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_sgddtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.208121</td>\n",
       "      <td>34.162835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_softdtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>43.630058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GNWT</td>\n",
       "      <td>bary-sq_softdtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.200055</td>\n",
       "      <td>23.446639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>3.262772</td>\n",
       "      <td>105.931994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_euclidean</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.612835</td>\n",
       "      <td>65.740546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>2.357553</td>\n",
       "      <td>92.368604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_dtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>1.120038</td>\n",
       "      <td>54.378516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_sgddtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>3.589925</td>\n",
       "      <td>99.305876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_sgddtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.800403</td>\n",
       "      <td>67.486909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_softdtw</td>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>1.406718</td>\n",
       "      <td>66.431056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IIT</td>\n",
       "      <td>bary-sq_softdtw</td>\n",
       "      <td>off</td>\n",
       "      <td>1</td>\n",
       "      <td>Abs</td>\n",
       "      <td>0.623904</td>\n",
       "      <td>35.698599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model                SPI stimulus_presentation  Noise Data_Type  \\\n",
       "0   GNWT  bary-sq_euclidean                    on      1       Abs   \n",
       "1   GNWT  bary-sq_euclidean                   off      1       Abs   \n",
       "2   GNWT        bary-sq_dtw                    on      1       Abs   \n",
       "3   GNWT        bary-sq_dtw                   off      1       Abs   \n",
       "4   GNWT     bary-sq_sgddtw                    on      1       Abs   \n",
       "5   GNWT     bary-sq_sgddtw                   off      1       Abs   \n",
       "6   GNWT    bary-sq_softdtw                    on      1       Abs   \n",
       "7   GNWT    bary-sq_softdtw                   off      1       Abs   \n",
       "8    IIT  bary-sq_euclidean                    on      1       Abs   \n",
       "9    IIT  bary-sq_euclidean                   off      1       Abs   \n",
       "10   IIT        bary-sq_dtw                    on      1       Abs   \n",
       "11   IIT        bary-sq_dtw                   off      1       Abs   \n",
       "12   IIT     bary-sq_sgddtw                    on      1       Abs   \n",
       "13   IIT     bary-sq_sgddtw                   off      1       Abs   \n",
       "14   IIT    bary-sq_softdtw                    on      1       Abs   \n",
       "15   IIT    bary-sq_softdtw                   off      1       Abs   \n",
       "\n",
       "    KL_Divergence          WD  \n",
       "0        0.259259   27.971548  \n",
       "1        0.261054   22.107636  \n",
       "2        0.289872   33.030310  \n",
       "3        0.205493   25.614307  \n",
       "4        0.264105   39.033546  \n",
       "5        0.208121   34.162835  \n",
       "6        0.268424   43.630058  \n",
       "7        0.200055   23.446639  \n",
       "8        3.262772  105.931994  \n",
       "9        0.612835   65.740546  \n",
       "10       2.357553   92.368604  \n",
       "11       1.120038   54.378516  \n",
       "12       3.589925   99.305876  \n",
       "13       0.800403   67.486909  \n",
       "14       1.406718   66.431056  \n",
       "15       0.623904   35.698599  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the KL divergence between the model and empirical data\n",
    "all_KL_results_list = []\n",
    "all_WD_results_list = []\n",
    "noise_level = 1\n",
    "for model in [\"GNWT\", \"IIT\"]:\n",
    "    for this_SPI in model_vs_empirical_across_geometries.SPI.unique():\n",
    "        for stim_type in ['on', 'off']:\n",
    "        \n",
    "            # Subset data\n",
    "            empirical_data_abs = model_vs_empirical_across_geometries.query(\"SPI==@this_SPI & stimulus_presentation == @stim_type & Model == @model & Data_Type == 'Empirical'\")['value']\n",
    "            model_data_abs = model_vs_empirical_across_geometries.query(\"SPI==@this_SPI & stimulus_presentation == @stim_type & Model == @model & Data_Type == 'Model' & Noise==@noise_level\")['value']\n",
    "\n",
    "            #### KL ####\n",
    "            # Absolute value data\n",
    "            this_model_noise_KL_abs = kl_divergence_from_counts(empirical_data_abs, model_data_abs, num_bins=100, units=\"bits\")\n",
    "            all_KL_results_list.append(pd.DataFrame({\"Model\": [model], \"SPI\": [this_SPI], \"stimulus_presentation\": [stim_type], \"Noise\": [noise_level], \"Data_Type\": [\"Abs\"], \"KL_Divergence\": [this_model_noise_KL_abs]}))\n",
    "\n",
    "            #### Wasserstein Distance ####\n",
    "            # Absolute value data\n",
    "            this_model_noise_WD_abs = wasserstein_distance(empirical_data_abs, model_data_abs)\n",
    "            all_WD_results_list.append(pd.DataFrame({\"Model\": [model], \"SPI\": [this_SPI], \"stimulus_presentation\": [stim_type], \"Noise\": [noise_level], \"Data_Type\": [\"Abs\"], \"WD\": [this_model_noise_WD_abs]}))\n",
    "\n",
    "# Concatenate the results\n",
    "all_KL_results = pd.concat(all_KL_results_list)\n",
    "all_WD_results = pd.concat(all_WD_results_list)\n",
    "\n",
    "# Merge the KL and WD results\n",
    "all_stats_results = pd.merge(all_KL_results, all_WD_results, on=['Model', 'SPI', 'stimulus_presentation', 'Noise', 'Data_Type'])\n",
    "all_stats_results.query(\"Noise == 1\").sort_values(['Data_Type', 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i all_stats_results\n",
    "\n",
    "all_stats_results %>% \n",
    "    pivot_longer(cols=c(KL_Divergence, WD), names_to=\"Statistic\", values_to=\"Value\") %>%\n",
    "    mutate(stimulus_presentation = factor(stimulus_presentation, levels=c(\"on\", \"off\")),\n",
    "           geometry = str_replace(SPI, \"bary-sq_\", \"\")) %>%\n",
    "    mutate(geometry = factor(geometry, levels=c(\"euclidean\", \"dtw\", \"softdtw\", \"sgddtw\"))) %>%\n",
    "    ggplot(data=., mapping=aes(x=geometry, y=Value, color=Model)) +\n",
    "    geom_point() +\n",
    "    geom_line(aes(group=Model)) +\n",
    "    scale_color_manual(values=c(\"IIT\" = \"#e96893\", \"GNWT\" = \"#5b8c00\")) +\n",
    "    facet_wrap(Statistic ~ stimulus_presentation, scales='free_y', ncol=1) +\n",
    "    scale_x_discrete(expand=c(0.05, 0.05)) +\n",
    "    theme(legend.position=\"none\",\n",
    "          strip.background = element_blank(),\n",
    "            strip.text.x = element_text(face='bold'),\n",
    "            strip.text.y = element_text(angle=0, face='bold'))\n",
    "\n",
    "ggsave(\"../plots/modeling/Barycenter_KL_WD_across_geometries.svg\", width=4, height=5, units='in', dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "annie_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
