{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0) # seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and input objects\n",
    "\n",
    "class network_model:\n",
    "    def __init__(self, num_nodes, weights, tau_X, tau_H, arousal,g,sigma):\n",
    "        self.num_nodes = num_nodes\n",
    "        self.W = weights\n",
    "        self.tau_X = tau_X\n",
    "        self.tau_H = tau_H\n",
    "        self.arousal = arousal\n",
    "        self.g = g\n",
    "        self.sigma = sigma\n",
    "\n",
    "class network_input:\n",
    "    def __init__(self, num_nodes, stim_onset, burnin, stim_offset, sim_length, lesion):\n",
    "        I_ext = np.zeros((num_nodes, sim_length))\n",
    "        I_ext[0, stim_onset + burnin:stim_offset + burnin] = 1\n",
    "        self.I_ext = I_ext\n",
    "        self.lesion = lesion \n",
    "\n",
    "# define solver\n",
    "\n",
    "def euler_maruyama(nw,input,DT,T,sim_length):\n",
    "\n",
    "    # Initial conditions / storage structures\n",
    "    X = np.zeros((nw.num_nodes, sim_length))\n",
    "    H = np.zeros((nw.num_nodes, sim_length))\n",
    "\n",
    "    # numerical integration\n",
    "    for tt in range(sim_length - 1):\n",
    "        \n",
    "        DX = (-X[:, tt] + np.maximum(nw.W @ X[:, tt] + input.I_ext[:, tt] - nw.g * H[:, tt] + input.lesion + nw.arousal, 0)) / nw.tau_X\n",
    "        DH = (-H[:, tt] + X[:, tt]) / nw.tau_H\n",
    "        DW_X = nw.sigma * np.sqrt(DT) * np.random.randn(nw.num_nodes)\n",
    "        DW_H = nw.sigma * np.sqrt(DT) * np.random.randn(nw.num_nodes)\n",
    "\n",
    "        X[:, tt + 1] = X[:, tt] + DT * DX + DW_X\n",
    "        H[:, tt + 1] = H[:, tt] + DT * DH + DW_H\n",
    "\n",
    "    return X, H\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### simulation params\n",
    "\n",
    "DT = 1   \n",
    "T = 3000\n",
    "sim_length = len(np.arange(0, T + DT, DT)) - 1\n",
    "\n",
    "#### shared model params\n",
    "\n",
    "arousal = 0.85\n",
    "tau_H = 400\n",
    "sigma = 0.005\n",
    "\n",
    "#### IIT model params\n",
    "n_nodes_IIT = 2\n",
    "tau_X_IIT = np.array([10, 20])\n",
    "W_v1_v1 = 0.1\n",
    "W_cs_v1 = 0.75\n",
    "W_v1_cs = 0.75\n",
    "W_cs_cs = 0.1\n",
    "\n",
    "g_IIT = 0.5 # weak adaptation\n",
    "\n",
    "W_IIT = np.array([[W_v1_v1, W_v1_cs],\n",
    "              [W_cs_v1, W_cs_cs]])\n",
    "\n",
    "IIT_net = network_model(n_nodes_IIT,W_IIT,tau_X_IIT,tau_H,arousal,g_IIT,sigma)\n",
    "\n",
    "#### GNWT model params\n",
    "n_nodes_GNWT = 3\n",
    "tau_X_GNWT = np.array([20, 50, 50])\n",
    "\n",
    "# CS\n",
    "W_cs1_cs1 = 0.05\n",
    "W_pfc1_cs1 = .75\n",
    "W_pfc2_cs1 = .75\n",
    "# PFC1\n",
    "W_cs1_pfc1 = 0.25\n",
    "W_pfc1_pfc1 = 0.25\n",
    "W_pfc2_pfc1 = -2.5\n",
    "# PFC2\n",
    "W_cs1_pfc2 = 0.25\n",
    "W_pfc1_pfc2 = -2.5\n",
    "W_pfc2_pfc2 = .25\n",
    "\n",
    "W_GNWT = np.array([[W_cs1_cs1, W_cs1_pfc1, W_cs1_pfc2],\n",
    "              [W_pfc1_cs1, W_pfc1_pfc1, W_pfc1_pfc2],\n",
    "              [W_pfc2_cs1,  W_pfc2_pfc1,  W_pfc2_pfc2]])\n",
    "\n",
    "g_GNWT = 1; # strong adaptation\n",
    "\n",
    "GNWT_net = network_model(n_nodes_GNWT,W_GNWT,tau_X_GNWT,tau_H,arousal,g_GNWT,sigma)\n",
    "\n",
    "#### shared input params\n",
    "burnin = int(500 / DT)\n",
    "stim_onset = int(500 / DT)\n",
    "stim_offset = int(1500 / DT)\n",
    "\n",
    "#### IIT input params\n",
    "v1_lesion = 0\n",
    "cs_lesion = 0\n",
    "lesion_IIT = np.array([v1_lesion, cs_lesion])\n",
    "\n",
    "IIT_input = network_input(n_nodes_IIT, stim_onset, burnin, stim_offset, sim_length, lesion_IIT)\n",
    "\n",
    "#### GNWT input params\n",
    "cs_lesion = 0\n",
    "pfc1_lesion = 0\n",
    "pfc2_lesion = 0\n",
    "lesion_GNWT = np.array([cs_lesion, pfc1_lesion, pfc2_lesion])\n",
    "\n",
    "GNWT_input = network_input(n_nodes_GNWT, stim_onset, burnin, stim_offset, sim_length, lesion_GNWT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run simulations \n",
    "N_sims = 1000\n",
    "\n",
    "X_IIT = np.zeros((n_nodes_IIT, sim_length,N_sims))\n",
    "H_IIT = np.zeros((n_nodes_IIT, sim_length,N_sims))\n",
    "X_GNWT = np.zeros((n_nodes_GNWT, sim_length,N_sims))\n",
    "H_GNWT = np.zeros((n_nodes_GNWT, sim_length,N_sims))\n",
    "\n",
    "for n in range(N_sims):\n",
    "    if n % 50 == 0:\n",
    "        print(n)\n",
    "    [X_IIT[:,:,n],H_IIT[:,:,n]] = euler_maruyama(IIT_net,IIT_input,DT,T,sim_length)\n",
    "    [X_GNWT[:,:,n],H_GNWT[:,:,n]] = euler_maruyama(GNWT_net,GNWT_input,DT,T,sim_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural activity figures\n",
    "\n",
    "# subtract baseline \n",
    "v1 = X_IIT[0,burnin:] - np.mean(X_IIT[0,burnin:stim_onset+burnin])\n",
    "CS_IIT = X_IIT[1,burnin:] - np.mean(X_IIT[0,burnin:stim_onset+burnin])\n",
    "\n",
    "PFC = np.squeeze(np.mean(X_GNWT[1:,burnin:],axis=0) - np.mean(np.mean(X_GNWT[1:,burnin:stim_onset+burnin], axis=1, keepdims=True)))\n",
    "CS_GNWT = X_GNWT[0,burnin:] - np.mean(X_GNWT[0,burnin:stim_onset+burnin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures \n",
    "\n",
    "example_trl = 5\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Subplot 1: Activity\n",
    "axs[0, 0].plot(X_GNWT[1:,:,example_trl].T)\n",
    "axs[0, 0].set_title('Simulated activity: PFC')\n",
    "axs[0, 0].legend(['PFC1', 'PFC2'])\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_ylabel('Neural activity (a.u.)')\n",
    "\n",
    "# Subplot 2: normalised activity\n",
    "axs[0, 1].plot(PFC[:,example_trl])\n",
    "axs[0, 1].set_title('Normalised activity: PFC')\n",
    "axs[0, 1].set_xlabel('Time')\n",
    "axs[0, 1].set_ylabel('Normalised activity (a.u.)')\n",
    "\n",
    "# Subplot 3: Stim on\n",
    "axs[1, 0].plot(X_GNWT[0,:,example_trl].T)\n",
    "axs[1, 0].set_title('Simulated activity: CS')\n",
    "axs[1, 0].set_xlabel('Time')\n",
    "axs[1, 0].set_ylabel('Neural activity (a.u.)')\n",
    "\n",
    "# Subplot 4: Stim off\n",
    "axs[1, 1].plot(CS_GNWT[:,example_trl])\n",
    "axs[1, 1].set_title('Normalised activity: CS')\n",
    "axs[1, 1].set_xlabel('Time')\n",
    "axs[1, 1].set_ylabel('Normalised activity (a.u.)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Subplot 1: Activity\n",
    "axs[0, 0].plot(X_IIT[1:,:,example_trl].T)\n",
    "axs[0, 0].set_title('Simulated activity: V1')\n",
    "axs[0, 0].legend(['V1'])\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_ylabel('Neural activity (a.u.)')\n",
    "\n",
    "# Subplot 2: normalised activity\n",
    "axs[0, 1].plot(v1[:,example_trl])\n",
    "axs[0, 1].set_title('Normalised activity: V1')\n",
    "axs[0, 1].set_xlabel('Time')\n",
    "axs[0, 1].set_ylabel('Normalised activity (a.u.)')\n",
    "\n",
    "# Subplot 3: Stim on\n",
    "axs[1, 0].plot(X_IIT[0,:,example_trl].T)\n",
    "axs[1, 0].set_title('Simulated activity: CS')\n",
    "axs[1, 0].set_xlabel('Time')\n",
    "axs[1, 0].set_ylabel('Neural activity (a.u.)')\n",
    "\n",
    "# Subplot 4: Stim off\n",
    "axs[1, 1].plot(CS_IIT[:,example_trl])\n",
    "axs[1, 1].set_title('Normalised activity: CS')\n",
    "axs[1, 1].set_xlabel('Time')\n",
    "axs[1, 1].set_ylabel('Normalised activity (a.u.)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the stim on and off time series and add measurment noise\n",
    "\n",
    "measurment_noise = 1\n",
    "\n",
    "#### IIT model\n",
    "v1_stim_on = v1[stim_onset:stim_offset] + np.random.randn(len(v1[stim_onset:stim_offset]),N_sims)*measurment_noise\n",
    "CS_IIT_stim_on = CS_IIT[stim_onset:stim_offset] + np.random.randn(len(CS_IIT[stim_onset:stim_offset]),N_sims)*measurment_noise\n",
    "v1_stim_off = v1[stim_offset:] + np.random.randn(len(v1[stim_offset:]),N_sims)*measurment_noise\n",
    "CS_IIT_stim_off = CS_IIT[stim_offset:] + np.random.randn(len(CS_IIT[stim_offset:]),N_sims)*measurment_noise\n",
    "\n",
    "# Combine into 2D array \n",
    "time_series_IIT_stim_on = np.array([CS_IIT_stim_on, v1_stim_on])\n",
    "time_series_IIT_stim_off = np.array([CS_IIT_stim_off, v1_stim_off])\n",
    "\n",
    "#### GNWT model\n",
    "PFC_stim_on = PFC[stim_onset:stim_offset] + np.random.randn(len(PFC[stim_onset:stim_offset]),N_sims)*measurment_noise\n",
    "CS_GNWT_stim_on = CS_GNWT[stim_onset:stim_offset] + np.random.randn(len(CS_GNWT[stim_onset:stim_offset]),N_sims)*measurment_noise\n",
    "PFC_stim_off = PFC[stim_offset:] + np.random.randn(len(PFC[stim_offset:]),N_sims)*measurment_noise\n",
    "CS_GNWT_stim_off = CS_GNWT[stim_offset:] + np.random.randn(len(CS_GNWT[stim_offset:]),N_sims)*measurment_noise\n",
    "\n",
    "# Combine into a 2D array \n",
    "time_series_GNWT_stim_on = np.array([CS_GNWT_stim_on, PFC_stim_on])\n",
    "time_series_GNWT_stim_off = np.array([CS_GNWT_stim_off, PFC_stim_off])\n",
    "\n",
    "# reshape for saving \n",
    "time_series_GNWT_stim_on = np.reshape(time_series_GNWT_stim_on, (2000, N_sims))\n",
    "time_series_GNWT_stim_off = np.reshape(time_series_GNWT_stim_off, (2000, N_sims))\n",
    "time_series_IIT_stim_on = np.reshape(time_series_IIT_stim_on, (2000, N_sims))\n",
    "time_series_IIT_stim_off = np.reshape(time_series_IIT_stim_off, (2000, N_sims))\n",
    "\n",
    "# save time series for plotting\n",
    "np.savetxt(\"GNWT_stim_on\", time_series_GNWT_stim_on, delimiter=\",\")\n",
    "np.savetxt(\"GNWT_stim_off\", time_series_GNWT_stim_off, delimiter=\",\")\n",
    "np.savetxt(\"IIT_stim_on\", time_series_IIT_stim_on, delimiter=\",\")\n",
    "np.savetxt(\"IIT_stim_off\", time_series_IIT_stim_off, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load time series for plotting\n",
    "time_series_GNWT_stim_on = np.loadtxt(\"GNWT_stim_on\", delimiter=\",\")\n",
    "time_series_GNWT_stim_off = np.loadtxt(\"GNWT_stim_off\", delimiter=\",\")\n",
    "time_series_IIT_stim_on = np.loadtxt(\"IIT_stim_on\", delimiter=\",\")\n",
    "time_series_IIT_stim_off = np.loadtxt(\"IIT_stim_off\", delimiter=\",\")\n",
    "\n",
    "# reshape for plotting\n",
    "time_series_GNWT_stim_on = np.reshape(time_series_GNWT_stim_on, (2,1000, N_sims))\n",
    "time_series_GNWT_stim_off = np.reshape(time_series_GNWT_stim_off, (2,1000, N_sims))\n",
    "time_series_IIT_stim_on = np.reshape(time_series_IIT_stim_on, (2,1000, N_sims))\n",
    "time_series_IIT_stim_off = np.reshape(time_series_IIT_stim_off, (2,1000, N_sims))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of simulated time series\n",
    "\n",
    "from tslearn.barycenters import euclidean_barycenter\n",
    "\n",
    "#### IIT\n",
    "\n",
    "# Compute the Euclidean barycenter\n",
    "barycenter_IIT_stim_on = euclidean_barycenter(time_series_IIT_stim_on)**2\n",
    "barycenter_IIT_stim_off = euclidean_barycenter(time_series_IIT_stim_off)**2\n",
    "\n",
    "# Compute the timepoint of max barycenter\n",
    "max_barycenter_IIT_stim_on = np.argmax(barycenter_IIT_stim_on, axis=0)\n",
    "max_barycenter_IIT_stim_off = np.argmax(barycenter_IIT_stim_off, axis=0)\n",
    "\n",
    "#### GNWT\n",
    "\n",
    "# Compute the Euclidean barycenter\n",
    "barycenter_GNWT_stim_on = euclidean_barycenter(time_series_GNWT_stim_on)**2\n",
    "barycenter_GNWT_stim_off = euclidean_barycenter(time_series_GNWT_stim_off)**2\n",
    "\n",
    "# Compute the timepoint of max barycenter\n",
    "max_barycenter_GNWT_stim_on = np.argmax(barycenter_GNWT_stim_on, axis=0)\n",
    "max_barycenter_GNWT_stim_off = np.argmax(barycenter_GNWT_stim_off, axis=0)\n",
    "\n",
    "# Figures of barycenter time series\n",
    "time = np.linspace(1, 3000, 3000)\n",
    "\n",
    "plt.figure(5)\n",
    "plt.plot(barycenter_IIT_stim_on)\n",
    "\n",
    "plt.figure(6)\n",
    "plt.plot(barycenter_IIT_stim_off)\n",
    "\n",
    "plt.figure(7)\n",
    "plt.plot(barycenter_GNWT_stim_on)\n",
    "\n",
    "plt.figure(8)\n",
    "plt.plot(barycenter_GNWT_stim_off)\n",
    "\n",
    "# histograms of max\n",
    "n_bins = round(np.sqrt(N_sims))\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(max_barycenter_IIT_stim_on, bins=n_bins)\n",
    "axs[1].hist(max_barycenter_IIT_stim_off, bins=n_bins)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs[0].hist(max_barycenter_GNWT_stim_on, bins=n_bins)\n",
    "axs[1].hist(max_barycenter_GNWT_stim_off, bins=n_bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
